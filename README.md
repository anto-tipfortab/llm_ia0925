# üèùÔ∏è Asistente Tur√≠stico de Tenerife

**Pr√°ctica Final - Large Language Models**

---

## Descripci√≥n

Chatbot conversacional que responde preguntas sobre Tenerife utilizando:

- **RAG (Retrieval-Augmented Generation)**: Respuestas basadas en una gu√≠a tur√≠stica local
- **Di√°logo Multiturno**: Mantiene el contexto de la conversaci√≥n
- **Function Calling**: Integraci√≥n con funci√≥n de predicci√≥n meteorol√≥gica
- **Interfaz Web**: Aplicaci√≥n Streamlit interactiva

![Streamlit App](assets/app_screenshot.png)

---

## Estructura del Proyecto

```
LLM_IA0925/
‚îú‚îÄ‚îÄ .env                    # Variables de entorno (API Key)
‚îú‚îÄ‚îÄ app.py                  # Aplicaci√≥n Streamlit
‚îú‚îÄ‚îÄ notebook.ipynb          # Notebook principal
‚îú‚îÄ‚îÄ assistant.log           # Archivo de logs (se genera autom√°ticamente)
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias
‚îú‚îÄ‚îÄ assets/                 # Im√°genes y recursos
‚îÇ   ‚îî‚îÄ‚îÄ app_screenshot.png
‚îú‚îÄ‚îÄ src/                    # M√≥dulos Python
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ conf.py             # Configuraci√≥n y par√°metros del modelo
‚îÇ   ‚îú‚îÄ‚îÄ logger.py           # Configuraci√≥n de logging
‚îÇ   ‚îú‚îÄ‚îÄ api_client.py       # Cliente OpenAI (clase OpenAIClient)
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py      # Carga de documentos (clase DataLoader)
‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py     # Chunking, embeddings y b√∫squeda (clase VectorStore)
‚îÇ   ‚îú‚îÄ‚îÄ rag_chain.py        # Cadena RAG con function calling (clase RAGChain)
‚îÇ   ‚îú‚îÄ‚îÄ weather_service.py  # Servicio de clima (clase WeatherService)
‚îÇ   ‚îî‚îÄ‚îÄ system_prompt.txt   # Prompt del sistema (ROCA)
‚îî‚îÄ‚îÄ data/
    ‚îî‚îÄ‚îÄ TENERIFE.pdf        # Gu√≠a tur√≠stica de Tenerife
```

---

## Instalaci√≥n

### 1. Clonar el proyecto

```bash
git clone https://github.com/anto-tipfortab/llm_ia0925.git
cd llm_ia0925
```

### 2. Crear entorno virtual (recomendado)

```bash
python -m venv venv

# Activar en Mac/Linux:
source venv/bin/activate

# Activar en Windows:
venv\Scripts\activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar API Key

Crear archivo `.env` en la ra√≠z del proyecto:

```
OPENAI_API_KEY=sk-tu-clave-aqui
```

### 5. A√±adir el PDF

Copiar `TENERIFE.pdf` a la carpeta `data/`.

---

## Uso

### Aplicaci√≥n Streamlit (Recomendado)

```bash
streamlit run app.py
```

Se abrir√° en el navegador en `http://localhost:8501`

**Caracter√≠sticas:**
- Interfaz de chat interactiva
- Sidebar con configuraci√≥n del modelo y estad√≠sticas
- Indicador de uso de funci√≥n de clima
- Bot√≥n para limpiar conversaci√≥n

### Ejecutar el notebook

```bash
jupyter notebook notebook.ipynb
```

### Probar desde consola

```bash
ipython -c "
from src.conf import PDF_PATH
from src.api_client import OpenAIClient
from src.data_loader import DataLoader
from src.vector_store import VectorStore
from src.rag_chain import RAGChain
from src.weather_service import WeatherService

# Setup
client = OpenAIClient()
loader = DataLoader(PDF_PATH)
pages = loader.load()

# Build RAG with weather function
vector_store = VectorStore()
vector_store.build_from_documents(pages)
weather_service = WeatherService(simulated=True)
rag = RAGChain(client, vector_store, weather_service=weather_service)

# Query about places
result = rag.query('¬øC√≥mo puedo subir al Teide?')
print(result['answer'])

# Query about weather (triggers function calling)
result = rag.query('¬øQu√© tiempo har√° ma√±ana?')
print(result['answer'])
"
```

---

## M√≥dulos

### `src/conf.py`
Configuraci√≥n centralizada:
- `OPENAI_API_KEY`: Clave de API
- `MODEL_CONFIG`: Par√°metros del modelo (model, temperature, max_tokens, top_p)
- `PDF_PATH`: Ruta al documento
- `CHUNK_SIZE`, `CHUNK_OVERLAP`: Configuraci√≥n para RAG

### `src/logger.py`
- `setup_logger()`: Crea instancia de logger
- `logger`: Instancia por defecto para usar en otros m√≥dulos

### `src/api_client.py`
Clase `OpenAIClient`:
- `test_connection()`: Verifica conexi√≥n con OpenAI
- `get_completion(messages)`: Obtiene respuesta del modelo
- `get_completion_with_functions(messages, tools)`: Para function calling

### `src/data_loader.py`
Clase `DataLoader`:
- `load()`: Carga el PDF y extrae p√°ginas
- `get_stats()`: Estad√≠sticas del documento
- `get_page(index)`: Contenido de una p√°gina espec√≠fica
- `get_all_text()`: Todo el texto concatenado

### `src/vector_store.py`
Clase `VectorStore`:
- `build_from_documents(pages)`: Divide en chunks, genera embeddings y almacena en ChromaDB
- `load_existing()`: Carga vector store existente desde disco
- `search(query, k)`: Busca los k chunks m√°s relevantes
- `search_with_scores(query, k)`: B√∫squeda con puntuaciones de similitud
- `get_chunk_stats()`: Estad√≠sticas de los chunks

### `src/rag_chain.py`
Clase `RAGChain`:
- `query(question, k)`: Procesa pregunta y devuelve respuesta con fuentes
- `clear_history()`: Limpia el historial de conversaci√≥n
- `get_history()`: Obtiene el historial actual

Soporta:
- Conversaci√≥n multiturno con gesti√≥n de historial
- Function calling integrado con WeatherService
- Retorna `tool_called: True/False` para indicar si se us√≥ una funci√≥n

### `src/weather_service.py`
Clase `WeatherService`:
- `get_weather(date, location)`: Obtiene pron√≥stico del tiempo
- `get_tool_schema()`: Retorna el schema JSON para OpenAI
- `parse_tool_call(tool_call)`: Parsea y ejecuta llamadas del LLM

Caracter√≠sticas:
- `simulated=True`: Genera datos realistas de clima tinerfe√±o (default)
- `simulated=False`: Preparado para API real (requiere `api_key`)
- Validaci√≥n con Pydantic (`WeatherRequest`, `WeatherResponse`)
- Manejo de errores: formato de fecha inv√°lido, fecha muy lejana, fechas pasadas
- Soporte para fechas en lenguaje natural ("ma√±ana", "hoy", "fin de semana")

### `src/system_prompt.txt`
Prompt del sistema usando metodolog√≠a ROCA:
- **R**ole: Define el rol del asistente
- **O**bjective: Objetivo principal
- **C**onstraints: Restricciones y l√≠mites
- **A**ction: C√≥mo debe responder

### `app.py`
Aplicaci√≥n Streamlit:
- Interfaz de chat interactiva
- Sidebar con configuraci√≥n y estad√≠sticas
- Cache de RAG chain para mejor rendimiento
- Gesti√≥n de historial de conversaci√≥n

---

## Par√°metros del Modelo

| Par√°metro | Valor | Justificaci√≥n |
|-----------|-------|---------------|
| model | gpt-4o-mini | Balance entre coste y calidad |
| temperature | 0.3 | Respuestas deterministas, menos alucinaciones |
| max_tokens | 1024 | Suficiente para respuestas detalladas |
| top_p | 0.9 | Respuestas enfocadas |

## Par√°metros de RAG

| Par√°metro | Valor | Justificaci√≥n |
|-----------|-------|---------------|
| chunk_size | 1000 | Tama√±o suficiente para contexto coherente |
| chunk_overlap | 200 | Evita cortar frases entre chunks |

## Par√°metros de Conversaci√≥n

| Par√°metro | Valor | Justificaci√≥n |
|-----------|-------|---------------|
| max_history | 5 | √öltimos 5 turnos de conversaci√≥n para mantener contexto sin exceder tokens |

---

## Autor

Antonio Rodriguez

## Licencia

MIT